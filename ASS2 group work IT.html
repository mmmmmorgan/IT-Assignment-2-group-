<!DOCTYPE html>
<html lang="en" dir="ltr">

<head>
    <meta charset="utf-8" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="Assignment Two - Group 11 Webpage" />

    <title>Group 11 - Assignment 2 Team Page</title>
    <link rel="stylesheet" href="ASS2 group web.css">
</head>

<body>

<div class="header">
  <h1>IT Technologies</h1>
</div>

<div class="navbar">
  <a href="ASS2 group work home.html">Team Profile</a>
  <a href="ASS2 group work Tools.html">Tools</a>
  <a href="ASS2 group work IJob.html">Ideal Job</a>
  <a href="ASS2 group work IData.html">Industry Data</a>
  <a href="ASS2 group work IWork.html">IT Work</a>
  <a href="ASS2 group work IT.html">IT Technologies</a>
  <a href="ASS2 group work PJ.html">Project Ideas</a>
  <a href="ASS2 group work home.html" class="right">Home</a>
  <a href="ASS2 group work GR.html">Group Reflection</a>
</div>

  <div class="main">
    <style>
      h2{front-family: 'Merriweather Sans', sans-serif; color:darkred;}</style>
<h2>Technologies – Surgical Robots</h2>
<p>Over the past century, robots have taken leaps and bound in revolutionising the way that people live their life in all sorts of ways. Often, the first thing that springs to mind when one pictures a robot is the classic image of a brutish robotic arm in a car factory, spinning and sending sparks flying at an alarming pace. But the talents of robots are myriad and diverse. A world away from the production line, the welding-arm has a distant relative: Robotic Surgery Devices. These complicated and precise machines perform intricate surgeries on human patients who are in dire need of medical care. </p>
<p>For twenty years, the most advanced surgical robots in active use across the world has been the da Vinci Surgical System, manufactured and designed by the American company Intuitive Surgical. Physically, the da Vinci Surgical System is a number of robotic arms which connect to a device positioned next to the operating table with a patient. The arms can be fitted with all manner of tools needed for surgery, as well as a postionable camera which provides useful footage. The arms are controlled by a surgeon who is usually positioned right next to the patient and the robot. Ever since its invention at the turn of the century, the da Vinci Surgical System has become widely accepted into medical practice. There are an estimated 6000 of them in operation worldwide.</p>
<p>Surgical robots can perform a variety of different sorts of surgeries, but the current models do have some flaws. The da Vinci Surgical System, which is mainly used for Hysterectomies (partial or complete removal of the womb) and Prostatectomies (partial or removal of the prostate). As technology progresses, it is inevitable that a robot will be built which can perform more complicated surgeries in other parts of the body. The da Vinci Surgical System also has a high price tag – nearly 2 million dollars. Because the device is so expensive, it means that it has a limited market penetration. For a system to become truly widespread, it should be cheap enough for any surgery to afford one. </p>
<p>The da Vinci Surgical System has revolutionised robotic surgeries, but progress is in the process of marching on. When it was designed in 1999, Intuitive Surgical took out a 20-year patent on its design. Now, twenty years on, other companies are vying for market space with new designs. One such design is the Intelligent Surgical Unit (ISU), from the American company Asensus Surgical. The ISU differs from its competitors because not all its functions are controlled carefully by human hand. It features a camera which can be controlled by an automatic computer program. The company is investigating machine learning, which it will use to control various aspects of its future designs. Another company making strides in surgical robot designs is Johnson and Johnson, with their device called Ottava. This year, the Ottava is undergoing clinical trials before it can make its way into operating theatres. Unlike other robots, the six arms of Ottava is attached to the operating table, in such a way that it creates no clutter for patients or surgeons. With medical giants like Johnson and Johnson muscling their way into the surgical robotics space, its clear that these devices are here to stay. </p>
<p>The advances that contribute most to the development of new surgical robots are those in the field of machine learning. With advances in machine learning, surgical robots would be able to perform parts of, or even whole simple, operations without the need for human handling.  This would revolutionise the practice of surgery entirely and change the way medical care is administered.  </p>
<p>The impact of having less involvement from a surgeon is obvious – it would mean cheaper and more effective surgeries would become available to more people more easily. One of the most notable changes would be the steep reduction in operating costs of surgeries. In parts of the world where finding properly trained professionals are scarce, it would mean lifesaving medical treatment could be shipped inside a box – no training needed. </p>
<p>Of course, fully automated surgeries are still a way off. What is most likely to change is more and more surgeons will adopt robotic assistance. This means that surgery will involve less assistants, which will result in a reduction of price. It will also reduce the margin of error, as properly programmed medical robots aren’t subject to the inconsistencies which plague human decision-making. </p>
<p>There are two groups of people who will be most affected by the advancement of surgical robotics technology. First and foremost, the surgeons. They will have to learn new systems and adapt to new tools. Patients, on the other hand, will hopefully be able to access their surgeries at a lower price point. There will no doubt be some resistance to the new technology, but as it proves its efficacy patients will surely accept it.</p>
<p>Surgical robotics follows the larger societal trend of the modern developed world, in that it is a form of automation. Automated industries necessarily involve less human involvement. It makes surgical assistants redundant, and in the future perhaps even the surgeons themselves. Already existing models replace several tools currently used in surgery. </p>
<p>I have never had surgery, and I am not planning to have one any time in the future. That said, if reliable surgical robotics became more prevalent, I could rest easy knowing that I could access cheaper and less fallible care – should I need it. I’m sure as my friends and I get older, all of us will need surgery of some sort. I can imagine a future where these devices are installed into homes for private citizens to use under the care of automated programs.</p>

<h2>Clouds, Services and Servers</h2>
<h4>What does it do?</h4>
<p>The innovation in cloud technology is a new model of cloud computing in which an organization takes advantage of a combination clouds, both public and private clouds, together, this is called Multi Cloud Model. This model works by being most commonly built on open-source technology such as Kubernetes, Rancher and Nomad, these systems are supported by all public cloud providers. With this system you can manage workloads across multiple clouds so that you can best optimize performance and be able to utilize best the cloud services an organization may have available. A multi cloud model can be leveraged for computational infrastructure, development, data warehousing, cloud storage, artificial intelligence (AI) and machine learning (ML), disaster recovery/business continuity, and many other specialized solutions. This new technology has been made possible by the development and growth that Cloud Computing has had, now that using cloud has become common place not just for organizations but also for the general public the market there is now for public and private clouds has allowed and given purpose for the use of Multi Cloud as now you can choose to use certain cloud services that are better for particular operations than others, organizations can choose from a variety of providers such as Amazon Web Services (AWS), Microsoft Azure, Google Cloud, Salesforce, IBM Cloud and VMWare who have all invested deeply into these services. Organizations can now leverage two or more cloud computing platforms to perform various tasks. </p>
<p>Another interesting innovation in this field is the implementation of artificial intelligence (AI) and machine learning (ML) solutions in data centers. With AI and ML, you can increase uptime, manage energy use, recognize possible threats promptly, and protect against cyber-attacks. This is all made possible as AI and ML technology is able capable of collecting and analyzing data such as system load, aisle temperatures, network traffic and humidity levels in each data hall, and then be able to learn what normal the normal data looks like for each of things and then be able spot anomalies then be able to act on specified triggers or set points with a protocol it has to service the issue. As a result, if one of the system loads exceeds a given threshold, cooling infrastructure may be scaled up or down to provide adequate cooling in the most energy efficient manner. Also, with this technology you are able to make near autonomous, or self-driven, data centers that can manage themselves using automation and M.L/A. I to automate numerous data center maintenance duties to the point that data centers can function without human participation. The move toward self-driven data center has been made possible with the emergence and growth of virtualization/containerization of servers and because almost all servers are handled by software rather than hardware, they are an ideal platform for automation. A self-driven data center can possibly save massive amounts on personnel costs while increasing uptime the uptime of the data center. As of right now this solution is not commonplace but it is likely that in the next couple of years it will become common place for data centers to be able to run autonomously and not require personnel for maintenance. </p>
<h4>Impact</h4>
<p>The impact artificial intelligence (AI) and machine learning (ML) will have in the future will be quite substantial especially in the networking field, if data centers become fully autonomous a lot of people's jobs will become redundant and current practices that are in place in data centers will have to be completely redone. In my opinion this will one of the biggest evolutions there has ever been in the networking field, because AI/ML automation can scale to analyze data at levels beyond human capabilities, the advancement of this technology will result in near-perfect efficiency and dependability while also lowering the costs that an organization may experience. </p>
<p>The impact that multi cloud model will have been that now organizations will not have to be stuck with one cloud environment and having to be reliant on it as well, this model will enable organizations to deploy workloads across different cloud environments in order to maximize value while avoiding risks tied to specific cloud environments. With this model an organization that is looking to scale up is able to scale their storage requirements quite flexibly up and down whenever it is required. With this model the whole cloud services industry is transforming you will no longer be having to sacrifice or making a compromise now an organization will be able to able to match their company needs with the best cloud services for each unique operation they have and not have to make compromise with each operation they have and be able to maximize performance for each operation.   </p>
<h4>How this will affact us</h4>
<p>Since technology more or less affects every aspect of 21st century life, from transport efficiency and safety, to access to food and healthcare, socialization and productivity. The power of the internet has enabled global communities to form and ideas and resources to be shared more easily. This new technology will continue to make the same difference it has been creating forever, in that it will make your life better to some extent. As with Multi Cloud technology and Autonomous data centers these technologies do not make a substantial difference in your life on your day-to-day basis but instead it effects in subtle ways such as that as consumer you will notice that a service may being running faster than it had previously was or that some service you were using before has had less problem and noticeably higher uptime. For me personally I believe with this new technology depending on how certain organizations decide to use it will cause my change in the way we use IT, especially with my personal job I believe with this technology it will support me and my colleagues that are working from home and will cut the dependence on having to work at an office all the way in the city. </p>

<h2>Machine Learning </h2>
<h4>What does it do?</h4>
<p>Machine learning is a type of artificial intelligence (AI) that enables software applications to become more accurate at getting relevant results without being explicitly programmed and structured to do so. It is used by many giant leading companies such as Facebook, and Google with their massive data usage. In reference to the common ‘AI taking our job’ and eventually controlling humans argument, machine learning is still a long way from reaching that state. Machine learning has been around for decades, since 1959 by Arthur Samuel in the field of computer gaming and AI. As of now, in 2022, machine learning is continuously improving. With the increasing power and availability of machine learning models, gain from model improvements has become minimal and machine learning is also improving with better data practices. Businesses are slowly and steadily incorporating AI into their company, for both external and internal applications. With the pandemic happening from 2020 until now, it has accelerated the development of new machine learning models to meet customer requirements. Machine learning is often divided into two categories: supervised and unsupervised learning. Supervised learning involves exposing a large amount of labelled data to a system to train the machine learning algorithm. For example, a machine algorithm can be trained to predict house prices in Australia. To achieve this, it will first gather a large amount of data on important aspects to consider when buying a house in Australia, such as median prices of houses…from thousands of houses in Australia, the machine can be trained to predict a brand new house’s price based on the data it leveraged from other houses. In contrast to supervised learning, unsupervised learning tasks the algorithm with identifying patterns of data on its own, without any labelling to assist. Unsupervised learning simply searches for data that can be grouped based on their similarities, as well as anomalies that stand out. An example of this type of learning is how Airbnb uses machine learning to cluster together houses available to book for rent by neighbourhood. There are also some more types of machine learning such as semi-supervised learning and reinforcement learning. Semi-supervised learning mixes between supervised and unsupervised learning. As the name suggests, it combines a minimal amount of labelled data (supervised learning) and a large amount of unlabelled data(unsupervised learning) to train the system. Reinforcement learning is the training of machine models to make an order of decisions. It is like a game, for example, a person learning how to play a computer game. When they play for the first time, they would not be familiar with the rules or strategies to play the game and may not be very good at the game. However, eventually, by looking at the relationship between the keyboard buttons pressed, mouse movement, and their overall performance in the game, they will get better and better. Google DeepMind’s Deep Q network also utilizes this type of learning, which has beaten humans in a large number of old-school games. Right now, machine learning can be used to gather data on recommending products on popular websites and applications like Amazon or Netflix. Machine learning is predicted to grow exponentially in the next few years, with the market growing to an estimated $117.19 billion by 2027, from just $8.43 billion in 2019. The close future of machine learning includes a much faster data recognition and structurization, as well as optimization for algorithms allowing it to be used in more diverse fields of operation. One technological development that contributes to this future is the like of quantum computing. It allows simultaneous multi-state operations, enabling much faster data processing. In 2019, it performed a task in 200 seconds, which would have taken the world’s fastest supercomputer 10,000 years to finish. Another advancement is AutoML(Automated Machine Learning), which involves automating the process of applying ML to real-life tasks. It significantly simplifies the process to allow people or businesses to use machine learning without being an expert in this field. </p>
<h4>Impact</h4>
<p>The development of machine learning will have a huge impact on a variety of different industries. Healthcare and Pharmacy, which uses a huge amount of data (patients’ data, records…) With the current advancement of ML, better treatments and predictions can be generated. In fields such as diseases prevention, it can analyze a much bigger range of variables accounted for predicting and preventing diseases compared to our traditional method of collecting data. EHR (Electronic health record) can also be improved as image processing and converting a bigger amount of data from different sources. Manufacturing on the other hand is a newcomer to the machine learning realm. According to a survey in 2020, only 9% of survey respondents are utilizing ML in their businesses. By applying ML in manufacturing, various processes can be facilitated and improved, such as monitoring equipment, predicting the quality of various products… reducing cost, and improving the supply chain…Another field is automotive and self-driving vehicles. Big companies like Honda and Tesla are among the car developers that focuses on the self-driving car. A fully autonomous vehicle can be a reality with the help of ML, as it can significantly improve path planning, pedestrian detection, and other features to continue improving the perception and navigation of autonomous vehicles. In terms of ‘robots taking people’s jobs’, machine learning would rather ‘redesign’ jobs than replace humans. Specific tasks within certain jobs will be replaced by machines, not the entire job, with some occupations more impacted than others. It will replace some human services from jobs in companies like Google, where a lot of data algorithm is used, whereas physical jobs like massage therapist will be along the least affected spectrum. </p>
<h4>How this will affact us</h4>
<p>In my daily life, machine learning development will cause a few changes, but nothing too extreme. Considering I am planning to get a Tesla car in the near future, the improved navigation and perception would definitely allow me to feel safer using an autonomous vehicle, thanks to machine learning. Personalized Digital Media is another daily life pro of machine learning. In the entertainment industry, streaming services such as Netflix and Spotify are what I use almost every single day. Better algorithms mean that there will be more useful recommendations, as well as some ability to eliminate buffering and low-quality playback, to get the best quality when I’m watching shows. However, there are some down-sides of ML that I can think of that will affect me personally and many others. With the current state of the economy, finding a job is considerably difficult for fresh graduates. Machine learning also plays a big role in the job hiring market, with a high percentage of resumes automatically rejected by companies through an AI with machine learning. When I finished Uni, it will be harder to get a job and requires more effort. A distant family member of mine is a bus driver and considering the rise of AI and ML, as well as the development of the autonomous vehicles, it may affect his occupation as there will be more and more self-driving cars and public transport, although it may be a while before that happens.  </p>

<h2>Cybersecurity</h2>
<h4>What does it do?</h4>
<p>Cybersecurity is the practice of protecting computer systems, networks, and programs from malicious digital attacks (Cisco, para. 1). In modern times, it has become essential for businesses and individuals working with technological systems to exercise proper cybersecurity in order to prevent all categories of data from theft and damage. </p>
<p>There are a wide range of cyberattacks that can be performed if the cybersecurity of an organization is not up to date or secured tightly. Most common types include: <br>Malware<br>Encompasses spyware, viruses, and worms. Malware uses vulnerabilities to breach a network when a user clicks a dangerous link or email attachment, and is used to install malicious software inside a system. Such software can result in denial to critical components of a network, stealing of confidential information from a memory source, or potentially disrupting and disabling a system inoperable.</p>
<p>Phishing<br>Involve sending mass amounts of fraudulent emails to unsuspecting users, often disguised as coming from a reliable source. Such emails, on the surface, appear to be legitimate, but link the recipient to malicious files or scripts designed to grant the cyber attacker access to a computer device, which may lead to further damage such as installation of malicious scripts, extracting data such as user information, financial info etc. </p>
<p>Man-in-the-middle<br>Occurs when a cyber attacker intercepts a two-party transaction, inserting themselves in the middle. From there, they are able to steal and manipulate data by interrupting traffic and communication between the two parties. This attack exploits security vulnerabilities of a network, such as unsecured public Wi-Fi. Often combined with malware or phishing.</p>
<p>Denial-of-Service (DOS)<br>DoS attacks work by flooding systems, servers, and/or networks with traffic to overload resources and bandwidth, thus rendering the systems unable to process and fulfill legitimate requests from the user. With the aim to saturate all of a system’s resources, legitimate service requests from users are unable to get a response due to system overload.</p>
<p>So how does cybersecurity deter/deter such attacks from occurring? Proper cybersecurity practices involve ensuring that the following topics are met to industry standard:</p>
<p>Authentication – Systems ensuring communication is authentic and involved parties are legitimate, ensuring that messages come from, and are sent to, where they are claimed to<br>Access control – The ability to limit and control the ability of a user within certain privileges and status<br>Data Confidentiality – Protection of transmitted data and traffic flow between a number of parties to ensure no unwanted eavesdroppers (such as MitM attackers)<br>Data Integrity – Ensures messages are not modified during transmission from one party to another<br> The future of cybersecurity is one that the world is heavily investing in, as the internet becomes a greater part of our lives. With the advancement of technology and globalization of the internet, International Data Corporation forecasts that worldwide cyber security spending will reach $174.7 billion USD in 2024, with security services the largest and fastest growing market segment. In modern days, computer hacks are now occurring every 39 seconds, with the use of automated scripts, further emphasizing the fact that cybersecurity is becoming increasingly more important. </p>
<p>In the coming decade, artificial intelligence (AI) will be heavily utilised by both cyber attackers and cybersecurity specialists alike. Experts in the field believe that AI will play a crucial role, as computer security algorithms develop and detect threats and breaches before it happens. Automation of defensive procedures that act faster than viruses would greatly increase the cybersecurity of a computer system/application. </p>
<h4>What is the likely impact?</h4>
<p>Cybesecurity is important in modern times, as well as the coming future, due to its ability to protect categories of data from theft and damage. This includes confidential, sensitive data, personally identifiable information, personal information, intellectual property, or even governmental data (Upguard 2022). </p>
<p>The development with the most potential comes from the emergence of AI technologies in the cybersecurity field, allowing for machines to detect weaknesses and cyberattacks in a computer system before they happen, as well as during the attack. AI can also serve as defence in the organization’s computer network system, maintaining the highest level of security automatically and configuring protocols and software optimally, which is a substantial improvement to the error-prone nature of humans.</p>
<p>With the ability to utilize artificial intelligence, there may be a high impact in the IT and cybersecurity industry as a whole, due to the fact that AI can potentially more optimally do the job better than humans can. Due to this, I believe that IT workers in the field that primarily handle the configuration of computer software and network systems will likely feel the most impact in this change, and not due to the fault of themselves, as AI and machine learning is a controversial topic in terms of the limited supply of jobs and the potential decrease in demand. However, the benefits of using AI technologies also serve as an incredible tool for organizations and businesses, as they may cut costs on salary while also improving the overall security of their computer infrastructure. The general public may also feel an impact in the sense that the software that is provided as general tools for cybersecurity for at-home computer systems and networks overtime are improved upon with machine learning and AI. The image of computer hardware including some form of cybersecurity software pre-installed, and thus the need for specific configuration from an IT expert decreases, is one that definitely portrays the outlook of not just cybersecurity fields, but the IT industry as a whole in the coming future. </p>
<h4>How will this affect you?</h4>
<p>In my daily life, if cybersecurity were to suddenly improve, the overall safety of my computer systems at home would be greatly increased. As a relatively technological person, I do have an Internet of Things setup at home, with cameras, smart-home technologies, a myriad of devices in which not just my own, but my families’ devices are also connected to on the local network. Early Internet-of-Things technologies definitely had major flaws in the cybersecurity area, as expected with the natural concern of technologies that involve voice recognition or video footage of the home itself. Cyberattacks were able to infiltrate the home computer networks of individuals due to the poor cybersecurity infrastructure. However, with the future of cybersecurity securely invested in, and the potential developments of technologies such as cybersecurity AI and infrastructure, the general public, such as myself, will definitely feel safer in using the latest technologies without concern for cyberattacks.</p>
<p>Further, in my personal goals to become a Senior Systems Administrator, the field of cybersecurity introducing potential technological developments like AI and machine learning only increases the prospect of attaining my ambitions. As a senior sysadmin, which generally works with a team and manages both sides of software and hardware, the improvements to technologies in the software side of things would greatly assist the daily activities on the job, reducing disruptions and performance in the computer systems and networks of a business or organization.</p>
<p>My family and friends, which undoubtedly also use a variety of computer systems and networks at both the residence and the workplace, as well as on-hand such as mobile phones and Bluetooth devices, will notice the errors and hiccups of computer networks/systems and overall quality of life in using products and services will increase. As the tech guy, often configuring the hardware and software settings, finding solutions online to the problems presented, they may even request less assistance from me. Thanks cybersecurity!</p>
</div>

<div class="footer">
<h3>Reference</h3>
<p>Crew, B., 2022. Worth the cost? A closer look at the da Vinci robot’s impact on prostate cancer surgery. [online] Nature.com. Available at: <<a href="https://www.nature.com/articles/d41586-020-01037-w">https://www.nature.com/articles/d41586-020-01037-w</a>>[Accessed 30 April 2022]. </p>
<p>Edwards, G., 2022. The patent power struggle in surgical robotics. [online] Med-Tech Innovation. Available at: <<a href="https://www.med-technews.com/medtech-insights/assessing-patents-in-surgical-robotics/">https://www.med-technews.com/medtech-insights/assessing-patents-in-surgical-robotics/</a>> [Accessed 30 April 2022]. </p>
<p>Intuitive.com. 2022. [online] Available at: <<a href="https://www.intuitive.com/en-us">https://www.intuitive.com/en-us</a>> [Accessed 30 April 2022].
</p>
<p>Sennaar, K., 2022. Machine Learning in Surgical Robotics - 4 Applications That Matter | Emerj Artificial Intelligence Research. [online] Emerj Artificial Intelligence Research. Available at: <<a href="https://emerj.com/ai-sector-overviews/machine-learning-in-surgical-robotics-4-applications/">https://emerj.com/ai-sector-overviews/machine-learning-in-surgical-robotics-4-applications/</a>> [Accessed 30 April 2022].
</p>
<p>The Economist. 2022. The kindness of strangers. [online] Available at: <<a href="https://www.economist.com/babbage/2012/01/18/the-kindness-of-strangers">https://www.economist.com/babbage/2012/01/18/the-kindness-of-strangers</a>> [Accessed 30 April 2022].
</p>
<p>Whooley, S., 2022. BREAKING: Johnson & Johnson finally unveils its new robot-assisted surgery system. [online] MassDevice. Available at: <<a href="https://www.massdevice.com/breaking-johnson-johnson-finally-unveils-its-new-robot-assisted-surgery-system/">https://www.massdevice.com/breaking-johnson-johnson-finally-unveils-its-new-robot-assisted-surgery-system/</a>> [Accessed 30 April 2022].
</p>
<p>Haranas, M., 2022. 10 Hot Data Center Technologies And Trends To Watch In 2021. [online] CRN. Available at: <<a href="https://www.massdevice.com/breaking-johnson-johnson-finally-unveils-its-new-robot-assisted-surgery-system/">https://www.massdevice.com/breaking-johnson-johnson-finally-unveils-its-new-robot-assisted-surgery-system/</a>> [Accessed 30 April 2022].
</p>
<p>Intelligent Data Centers. 2022. How AI and Machine Learning are set to change the game for data center operations - Intelligent Data Centers. [online] Available at: <<a href="https://www.intelligentdatacentres.com/2022/02/15/how-ai-and-machine-learning-are-set-to-change-the-game-for-data-centre-operations/">https://www.intelligentdatacentres.com/2022/02/15/how-ai-and-machine-learning-are-set-to-change-the-game-for-data-centre-operations/</a>> [Accessed 20 April 2022].
</p>
<p>Techtarget.com. 2022. 5 Technologies that Could Change Networking in 2020. [online] Available at: <<a href="https://www.techtarget.com/searchunifiedcommunications/DigitalTransformation/5-Technologies-that-Could-Change-Networking-in-2020">https://www.techtarget.com/searchunifiedcommunications/DigitalTransformation/5-Technologies-that-Could-Change-Networking-in-2020</a>> [Accessed 19 April 2022].
</p>
<p>VMware. 2022. What is Multi-Cloud? | VMware Glossary. [online] Available at: <<a href="https://www.vmware.com/topics/glossary/content/multi-cloud.htm">https://www.vmware.com/topics/glossary/content/multi-cloud.htm</a>> [Accessed 19 April 2022].
</p>
<p>Burns, E. (n.d.). What Is Machine Learning and Why Is It Important? [online] SearchEnterpriseAI. <a href="https://www.techtarget.com/searchenterpriseai/definition/machine-learning-ML#:~:text=Machine%20learning%20(ML)%20is%20a.">https://www.techtarget.com/searchenterpriseai/definition/machine-learning-ML#:~:text=Machine%20learning%20(ML)%20is%20a. </a>
</p>
<p>Heath, N. (2018). What is machine learning? Everything you need to know. [online] ZDNet. Available at: <a href="https://www.zdnet.com/article/what-is-machine-learning-everything-you-need-to-know/. ">https://www.zdnet.com/article/what-is-machine-learning-everything-you-need-to-know/. </a></p>
<p>Anadiotis, G. (n.d.). The state of AI in 2021: Machine learning in production, MLOps and data-centric AI. [online] ZDNet. Available at: <a href="https://www.zdnet.com/article/the-state-of-ai-in-2021-machine-learning-in-production-mlops-and-data-centric-ai/.">https://www.zdnet.com/article/the-state-of-ai-in-2021-machine-learning-in-production-mlops-and-data-centric-ai/.</a></p>
<p>Cisco, What is Cybersecurity?<a href="https://www.cisco.com/c/en_au/products/security/what-is-cybersecurity.html">https://www.cisco.com/c/en_au/products/security/what-is-cybersecurity.html.</a></p>
<p>Fichtner, E 2022, Cybersecurity 101: Intro to the Top 10 Common Types of Cybersecurity Attacks,<a href="https://www.datto.com/au/blog/cybersecurity-101-intro-to-the-top-10-common-types-of-cybersecurity-attacks">https://www.datto.com/au/blog/cybersecurity-101-intro-to-the-top-10-common-types-of-cybersecurity-attacks.</a></p>
<p>Tunggal, A. T 2022, Why is Cybersecurity Important?,<a href="https://www.upguard.com/blog/cybersecurity-important#:~:text=Cybersecurity%20is%20important%20because%20it,governmental%20and%20industry%20information%20systems">https://www.upguard.com/blog/cybersecurity-important#:~:text=Cybersecurity%20is%20important%20because%20it,governmental%20and%20industry%20information%20systems.</a></p>

</div>
